{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fa3433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîä Listening on 'trades'...\n",
      "üÜï Incoming from Exoplanet at 1750927107: 1 action(s)\n",
      "  - BUY ‚Üí ADA (Quantity: 2.59)\n",
      "üÜï Incoming from Asteroid at 1750927107: 1 action(s)\n",
      "  - SELL ‚Üí XRP (Quantity: 6.13)\n",
      "\n",
      "üì¶ Next trading batch at 1750927110 from 2 trader(s), 2 action(s):\n",
      "  1. BUY ‚Üí ADA (Quantity: 2.59) from Exoplanet at 1750927107\n",
      "  2. SELL ‚Üí XRP (Quantity: 6.13) from Asteroid at 1750927107\n",
      "‚úÖ [Time:1750927115.6812797] Executed BUY for ADA (2.59) by Exoplanet at 1750927107\n",
      "‚úÖ [Time:1750927115.6815867] Executed SELL for XRP (6.13) by Asteroid at 1750927107\n",
      "\n",
      "üì¶ Next trading batch at 1750927120 from 0 trader(s), 0 action(s):\n",
      "üÜï Incoming from Exoplanet at 1750927128: 2 action(s)\n",
      "  - BUY ‚Üí ETH (Quantity: 3.92)\n",
      "  - BUY ‚Üí BTC (Quantity: 7.04)\n",
      "üÜï Incoming from Asteroid at 1750927128: 2 action(s)\n",
      "  - BUY ‚Üí BTC (Quantity: 3.9)\n",
      "  - SELL ‚Üí ETH (Quantity: 6.57)\n",
      "\n",
      "üì¶ Next trading batch at 1750927131 from 2 trader(s), 4 action(s):\n",
      "  1. BUY ‚Üí ETH (Quantity: 3.92) from Exoplanet at 1750927128\n",
      "  2. BUY ‚Üí BTC (Quantity: 7.04) from Exoplanet at 1750927128\n",
      "  3. BUY ‚Üí BTC (Quantity: 3.9) from Asteroid at 1750927128\n",
      "  4. SELL ‚Üí ETH (Quantity: 6.57) from Asteroid at 1750927128\n",
      "‚úÖ [Time:1750927136.6882622] Executed BUY for ETH (3.92) by Exoplanet at 1750927128\n",
      "‚úÖ [Time:1750927136.6885397] Executed BUY for BTC (7.04) by Exoplanet at 1750927128\n",
      "‚úÖ [Time:1750927136.6886313] Executed BUY for BTC (3.9) by Asteroid at 1750927128\n",
      "‚úÖ [Time:1750927136.68871] Executed SELL for ETH (6.57) by Asteroid at 1750927128\n",
      "Stopping...\n",
      "‚ùå Listener thread crashed: I/O operation on closed file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Next trading batch at 1750927141 from 0 trader(s), 0 action(s):\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "import redis\n",
    "import json\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "from queue import Queue\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, UTC\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TradeSubscriber:\n",
    "    \"\"\"\n",
    "    TradeSubscriber listens to a Valkey/Redis PubSub channel and processes trading actions.\n",
    "\n",
    "    - Uses two threads:\n",
    "      - One for listening to the channel and buffering messages\n",
    "      - One for batching and processing the buffered messages asynchronously\n",
    "\n",
    "    - Ensures no messages are lost by buffering all received data and processing it in bulk.\n",
    "    \"\"\"\n",
    "    host: str = 'localhost'\n",
    "    port: int = 6379\n",
    "    channel: str = 'trades'\n",
    "    queue: Queue = field(default_factory=Queue)\n",
    "    stop_event: threading.Event = field(default_factory=threading.Event)\n",
    "    buffer: List[Dict] = field(default_factory=list)  # stores all received batches\n",
    "    frequency: int = 5  # seconds between processing batches\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Redis client and subscribe to the configured channel.\n",
    "        \"\"\"\n",
    "        self.client = redis.Redis(host=self.host, port=self.port)\n",
    "        self.pubsub = self.client.pubsub()\n",
    "        self.pubsub.subscribe(self.channel)\n",
    "    \n",
    "    def _never_end(self):\n",
    "        \"\"\"\n",
    "        Keeps the main thread alive to prevent early exit and allows keyboard interruption.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(1)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopping...\")\n",
    "            self.stop()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Starts the subscriber by launching the listener and processor threads,\n",
    "        then keeps the main thread alive.\n",
    "        \"\"\"\n",
    "        threading.Thread(target=self._listen, daemon=True).start()\n",
    "        threading.Thread(target=self._process, daemon=True).start()\n",
    "        self._never_end()\n",
    "\n",
    "    def _listen(self):\n",
    "        \"\"\"\n",
    "        Background thread that listens for incoming PubSub messages.\n",
    "        Gracefully exits on stop signal or Redis disconnection.\n",
    "        \"\"\"\n",
    "        print(f\"üîä Listening on '{self.channel}'...\")\n",
    "        try:\n",
    "            for message in self.pubsub.listen():\n",
    "                if self.stop_event.is_set():\n",
    "                    break\n",
    "                if message['type'] != 'message':\n",
    "                    continue\n",
    "                try:\n",
    "                    data = json.loads(message['data'].decode())\n",
    "\n",
    "                    # Log the new incoming batch\n",
    "                    trader = data.get(\"trader\", \"Unknown\")\n",
    "                    ts = data.get(\"timestamp\")\n",
    "                    actions = data.get(\"actions\", [])\n",
    "                    print(f\"üÜï Incoming from {trader} at {ts}: {len(actions)} action(s)\")\n",
    "                    for action in actions:\n",
    "                        crypto = action.get('crypto')\n",
    "                        act = action.get('action')\n",
    "                        quantity = action.get('quantity', 'N/A')\n",
    "                        print(f\"  - {act.upper()} ‚Üí {crypto} (Quantity: {quantity})\")\n",
    "\n",
    "                    self.buffer.append(data)\n",
    "                    self.queue.put(data)\n",
    "\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ùå JSON decode error: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Unexpected message handling error: {e}\")\n",
    "\n",
    "        except redis.exceptions.ConnectionError as e:\n",
    "            # Expected on shutdown: server closes connection\n",
    "            if not self.stop_event.is_set():\n",
    "                print(f\"‚ùå Redis connection lost unexpectedly: {e}\")\n",
    "            else:\n",
    "                print(\"üõë Redis connection closed cleanly.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Listener thread crashed: {e}\")\n",
    "\n",
    "    def _process(self):\n",
    "        \"\"\"\n",
    "        Background thread that runs the asynchronous processing logic.\n",
    "        It wakes periodically, checks the buffer, and runs trading logic in bulk.\n",
    "        \"\"\"\n",
    "        asyncio.run(self._run_async_orders())\n",
    "\n",
    "    async def _run_async_orders(self):\n",
    "        \"\"\"\n",
    "        Asynchronous loop that waits on a timer and the trigger queue.\n",
    "        Once triggered, it processes all buffered batches together.\n",
    "        \"\"\"\n",
    "        while not self.stop_event.is_set():\n",
    "            time.sleep(self.frequency)  # ensure minimum time between batches\n",
    "            try:\n",
    "                self.queue.get(timeout=1)  # wakes processor\n",
    "                await self.handle_all_buffered_batches()\n",
    "            except Exception:\n",
    "                continue  # in case of timeout or queue empty\n",
    "\n",
    "    async def handle_all_buffered_batches(self):\n",
    "        \"\"\"\n",
    "        Processes all buffered batches together:\n",
    "        - Flattens all actions across traders\n",
    "        - Logs the batch header\n",
    "        - Executes all actions asynchronously\n",
    "        \"\"\"\n",
    "        all_actions = []\n",
    "        traders = set()\n",
    "        timestamps = []\n",
    "\n",
    "        # Collect all actions across all buffered batches\n",
    "        for batch in self.buffer:\n",
    "            timestamps.append(batch.get('timestamp'))\n",
    "            traders.add(batch.get('trader', 'Unknown'))\n",
    "            for action in batch.get('actions', []):\n",
    "                all_actions.append({\n",
    "                    \"trader\": batch.get('trader', 'Unknown'),\n",
    "                    \"timestamp\": batch.get('timestamp'),\n",
    "                    **action\n",
    "                })\n",
    "\n",
    "        self.buffer.clear()  # clear buffer after capturing its contents\n",
    "\n",
    "        # Use the most recent timestamp to tag the batch\n",
    "        batch_time = int(time.time())\n",
    "\n",
    "        print(f\"\\nüì¶ Next trading batch at {batch_time} from {len(traders)} trader(s), {len(all_actions)} action(s):\")\n",
    "\n",
    "        tasks = []\n",
    "        for i, action in enumerate(all_actions, 1):\n",
    "            trader = action.get('trader')\n",
    "            crypto = action.get('crypto')\n",
    "            act = action.get('action')\n",
    "            quantity = action.get('quantity', 'N/A')\n",
    "            creation_timestamp = action.get('timestamp')\n",
    "            print(f\"  {i}. {act.upper()} ‚Üí {crypto} (Quantity: {quantity}) from {trader} at {creation_timestamp}\")\n",
    "            tasks.append(self.execute_order(trader, act, crypto, quantity, timestamp=creation_timestamp))\n",
    "\n",
    "        await asyncio.gather(*tasks)  # run all tasks concurrently\n",
    "\n",
    "    async def execute_order(self, trader, action, crypto, quantity, timestamp):\n",
    "        \"\"\"\n",
    "        Simulates the execution of a single trade order with latency.\n",
    "        \"\"\"\n",
    "        await asyncio.sleep(5)  # simulate external I/O latency\n",
    "        execution_time = time.time()\n",
    "        print(f\"‚úÖ [Time:{execution_time}] Executed {action.upper()} for {crypto} ({quantity}) by {trader} at {timestamp}\")\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Triggers a clean shutdown of listener and processor threads.\n",
    "        \"\"\"\n",
    "        self.stop_event.set()\n",
    "        try:\n",
    "            self.pubsub.close()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to close pubsub: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    subscriber = TradeSubscriber()\n",
    "    subscriber.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valkey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
